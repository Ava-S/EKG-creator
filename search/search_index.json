{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PromG Library","text":"<p><code>PromG</code> collects queries for modeling, importing, enriching and analyzing event data as Event Knowledge Graphs (EKGs). The queries are run against a Neo4j instance. </p> <p>All scripts and queries are licensed under LGPL v3.0, see LICENSE. Copyright information is provided within each Project.</p> <p>This site contains the project documentation for <code>PromG</code>.</p>"},{"location":"#table-of-contents","title":"Table Of Contents","text":"<ol> <li>Tutorials</li> <li>How-To Guides</li> <li>Modules<ol> <li>Database Management Modules<ol> <li>Database Manager</li> </ol> </li> <li>Data Storage<ol> <li>Data Importer</li> <li>Transformer</li> <li>Exporter</li> </ol> </li> <li>Inference<ol> <li>Inference Engine</li> </ol> </li> <li>Analysis<ol> <li>Process Model Disovery</li> </ol> </li> </ol> </li> <li> <p>Explanation</p> </li> <li> <p>PromG Documentation: index.md tutorials.md</p> </li> <li>How-To Guides: how-to-guides.md</li> <li>Modules:<ul> <li></li> </ul> </li> <li>explanation.md</li> </ol> <p>Quickly find what you're looking for depending on your use case by looking at the different pages.</p>"},{"location":"#get-started","title":"Get started","text":""},{"location":"#promg","title":"PromG","text":"<p>The library can be installed in Pyhton using pip <code>pip install promg</code>.</p>"},{"location":"#neo4j","title":"Neo4j","text":"<p>The library assumes that Neo4j is installed.</p> <p>Install Neo4j:</p> <ul> <li>Use the Neo4j Desktop  (recommended), or</li> <li>Neo4j Community Server</li> </ul>"},{"location":"#create-a-new-graph-database","title":"Create a new graph database","text":"<ul> <li>The scripts in this release assume password \"12345678\".</li> <li>The scripts assume the server to be available at the default URL <code>bolt://localhost:7687</code></li> <li>You can modify this also in the script.</li> <li>ensure to allocate enough memory to your database, advised: <code>dbms.memory.heap.max_size=5G</code></li> <li>the script expects the <code>Neo4j APOC library</code> to be installed as a plugin, see https://neo4j.com/labs/apoc/</li> </ul> <p>For example projects that use this library, have a look at EKG BPI Challenges, EKG Inferring missing identifiers and EKG for AutoTwin EU GA n. 101092021.</p>"},{"location":"#projectsmodules","title":"Projects/Modules","text":"<p>The following projects are part of this repository</p>"},{"location":"#event-knowledge-graphs","title":"Event Knowledge Graphs","text":"<p>We use Event Knowledge Graphs as basis for our data model as they already naturally model Events, Activities, Entities and their relations for Process Mining. The EKGs are stored in a labeled property graph in Neo4J.</p>"},{"location":"#publications","title":"Publications","text":"<ul> <li>Stefan Esser, Dirk Fahland: Multi-Dimensional Event Data in Graph   Databases. CoRR abs/2005.14552, Journal on Data Semantics, DOI: 10.1007/s13740-021-00122-1 (   2020)</li> <li>Esser, Stefan. (2020, February 19). A Schema Framework for Graph Event Data. Master thesis. Eindhoven University of   Technology. https://doi.org/10.5281/zenodo.3820037</li> </ul>"},{"location":"#oced-pg","title":"OCED-PG","text":"<p>We developed a reference implementation for Object-Centric Event Data OCED. OCED-PG is a declarative extract-load-transformT framework, that maps the raw data to a corresponding EKG, using the semantic header as a basis.</p> <p>We proposed a three-layer approach to create a semantic-aware representation and storage system for OCED. </p> <ul> <li> <p>Base ontology: The OCED proposal is formalized as a PG-schema [1] providing a common interface for process querying. The schema defines a base ontology for representing and transforming OCED, which includes a semantic layer (defining the OCED concepts) and a record layer (defining concepts for generic data records from a legacy system and how they are related to the semantic layer). </p> </li> <li> <p>Reference ontology: The base ontology is specialized into a domain-specific reference ontology using PG-schema's inheritance mechanism. The reference ontology includes a semantic layer (defining the domain's semantic objects, events, and relations), and a record layer (defining in which legacy records the domain-level concepts are stored). The structural definitions are extended with rules to transform data in the record layer into nodes and relationships of the semantic layer, similar to ontology-based data access.</p> </li> <li>OCED-PG: declarative extract-load-transform (ELT) framework. OCED-PG load the legacy data records into the graph DB as a record layer. We then transform the data records into OCED by automatically translating the transformation rules of step (2) into queries over the record layer.</li> </ul>"},{"location":"#multi-process-discovery-and-analysis","title":"Multi-process Discovery and Analysis","text":""},{"location":"#publications_1","title":"Publications","text":""},{"location":"#task-identification","title":"Task Identification","text":""},{"location":"#publications_2","title":"Publications","text":""},{"location":"#custom-modules","title":"Custom Modules","text":""},{"location":"#missing-case-identifiers-inference","title":"Missing Case Identifiers Inference","text":"<p>Method to infer missing case identifiers in event data by exploiting knowledge about the activities and their locations.</p>"},{"location":"#publications_3","title":"Publications","text":""},{"location":"#scripts","title":"Scripts","text":""},{"location":"#main-script","title":"Main script","text":"<p>There is one script (orchestrator) that is used by applications to create an Event Knowledge graph. This script makes use of the library.</p>"},{"location":"#data_managers","title":"Data_managers","text":"<ul> <li>data_managers/datastructures.py --&gt; transforms the JSON file describing the different datasets into a class + additional methods</li> <li>data_managers/semantic_header.py --&gt; transforms the JSON file describing the semantic header into a class + additional methods</li> <li>data_managers/interpreters.py --&gt; Class that contains information about in what query language the semantic header and data structures should be interpreter</li> </ul>"},{"location":"#database_managers","title":"Database_managers","text":"<ul> <li>database_managers/authentication.py  --&gt; class containing the credentials to create connection to database. Local credentials are includes. In case you want to create a remote connection, add the following piece of code to a (gitignored) file.</li> </ul> <pre><code>remote = Credentials(\n    uri=\"[your_uri]\",\n    user=\"neo4j\",\n    password=\"[your_password]\"\n)\n</code></pre> <ul> <li>database_managers/db_connection.py --&gt; class responsible for making the connection to the database and to communicate with the database</li> <li>database_managers/EventKnowledgeGraph.py --&gt; class responsible for making (changes to) the EKG and to request data from the EKG. Makes use of several modules.</li> </ul>"},{"location":"#ekg_modules","title":"EKG_Modules","text":"<ul> <li>ekg_modules/db_management.py --&gt; general module to manage the database</li> <li>ekg_modules/data_importer.py --&gt; imports the data stored in the records into the EKG</li> <li>ekg_modules/ekg_builder_semantic_header.py --&gt; creates the required nodes and relations as specified in the semantic header</li> <li>ekg_modules/inference_engine.py --&gt; module responsible for inferring missing information</li> <li>ekg_modules/ekg_analysis.py --&gt; module for analysis of the EKG (e.g. create process model)</li> <li>ekg_modules/ekg_custom_module.py --&gt; module to create custom queries, specific for this example</li> </ul>"},{"location":"#cypherqueries","title":"CypherQueries","text":"<p>Contains repeatable pieces of Cypher Queries for all necessary parts. - cypher_queries/query_translators --&gt; translate semantic header and data structures into Cypher - cypher_queries/query_library --&gt; contains all cypher queries for the EKG modules - cypher_queries/custom_query_library --&gt; contains all custom cypher queries for this example for the EKG modules</p>"},{"location":"module-0verview/","title":"Module 0verview","text":"<p>This part of the project documentation focuses on an information-oriented approach. Use it as a reference for the technical implementation of the <code>PromG</code> project code.</p>"},{"location":"module-0verview/#core-modules","title":"Core Modules","text":""},{"location":"module-0verview/#table-of-contents","title":"Table Of Contents","text":"<ol> <li>Database Management Modules<ol> <li>Database Manager</li> </ol> </li> <li>Data Storage<ol> <li>Data Importer</li> <li>Transformer</li> <li>Exporter</li> </ol> </li> <li>Inference<ol> <li>Inference Engine</li> </ol> </li> <li>Analysis<ol> <li>Process Model Disovery</li> </ol> </li> </ol>"},{"location":"module-data-importer/","title":"Module: Database Manager","text":""},{"location":"module-data-importer/#promg.modules.data_importer.Importer","title":"<code>Importer</code>","text":"<p>Create Importer module</p> <p>Imports data using the dataset description files</p> <p>Parameters:</p> Name Type Description Default <code>data_structures</code> <code>DatasetDescriptions</code> <p>DatasetDescriptions object describing the different datasets</p> required <code>use_sample</code> <code>bool</code> <p>boolean indicating whether a sample can be used</p> <code>False</code> <code>use_preprocessed_files</code> <code>bool</code> <p>boolean indicating that preprocessed files can be used</p> <code>False</code> <p>Examples:</p> <p>Example without sample and preprocessed files</p> <pre><code>&gt;&gt;&gt; from promg.modules.data_importer import Importer\n&gt;&gt;&gt; # set dataset name\n&gt;&gt;&gt; dataset_name = 'BPIC17'\n&gt;&gt;&gt; # location of json file with dataset_description\n&gt;&gt;&gt; ds_path = Path(f'json_files/{dataset_name}_DS.json')\n&gt;&gt;&gt; dataset_descriptions = DatasetDescriptions(ds_path)\n&gt;&gt;&gt; importer = Importer(data_structures = dataset_descriptions)\nThe module to import data is returned.\nThe module won't use a sample, nor the preprocessed files\n</code></pre> <p>Example with sample and preprocessed files</p> <pre><code>&gt;&gt;&gt; from promg.modules.data_importer import Importer\n&gt;&gt;&gt; # set dataset name\n&gt;&gt;&gt; dataset_name = 'BPIC17'\n&gt;&gt;&gt; # location of json file with dataset_description\n&gt;&gt;&gt; ds_path = Path(f'json_files/{dataset_name}_DS.json')\n&gt;&gt;&gt; dataset_descriptions = DatasetDescriptions(ds_path)\n&gt;&gt;&gt; importer = Importer(data_structures = dataset_descriptions,\n&gt;&gt;&gt;                     use_sample = True,\n&gt;&gt;&gt;                     use_preprocessed_files = True)\nThe module to import data is returned.\nThe module will use the sample and the preprocessed files\nif they exist, in case they do not exist, they are created\n</code></pre>"},{"location":"module-data-importer/#promg.modules.data_importer.Importer.import_data","title":"<code>import_data()</code>","text":"<p>Method that imports the data records into the graph database as (:Record) nodes. The records contain the attributes as described in the dataset descriptions. Method also adds the specific record labels as specified by the semantic header.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; importer.import_data()\nThe records of the dataset described in the dataset descriptions are imported as (:Record) nodes with\nappropriate attributes and labels\n</code></pre>"},{"location":"module-db-management/","title":"Module: Database Manager","text":""},{"location":"module-db-management/#promg.modules.db_management.DBManagement","title":"<code>DBManagement</code>","text":"<p>Create DBManagement module</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from promg.modules.db_management import DBManagement\n&gt;&gt;&gt; db_manager = DBManagement()\n</code></pre>"},{"location":"module-db-management/#promg.modules.db_management.DBManagement.clear_db","title":"<code>clear_db(replace=True)</code>","text":"<p>Replace or clear the entire database by a new one.</p> Note <p>Note about difference between replacing and clearing.</p> <ul> <li> <p>Replace: results in an Empty database that is completely replaced with a new database.</p> <ul> <li>Replacing a database is faster than clearing a database.</li> <li>Only possible when<ul> <li>you have an Neo4j enterprise license</li> <li>you are running a local instance on the free Neo4j desktop version</li> </ul> </li> </ul> </li> <li> <p>Clear: Results in an empty database, however constraints are still in place.</p> <ul> <li>Clearing a database takes longer</li> <li>Independent of license</li> </ul> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>replace</code> <code>bool</code> <p>boolean to indicate whether the database may be replaced</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; db_manager.clear(replace=True)\nResults in an Empty database that is completely replaced with a new database\n    (i.e. constraints are also removed)\n</code></pre> <pre><code>&gt;&gt;&gt; db_manager.clear(replace=False)\nResults in an empty database, however constraints are still in place.\nClearing an entire database takes longer.\n</code></pre>"},{"location":"module-db-management/#promg.modules.db_management.DBManagement.set_constraints","title":"<code>set_constraints()</code>","text":"<p>Set constraints in Neo4j instance.</p> <ul> <li>sysId property is used as index for (:Entity) nodes</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; db_managers.set_constraints()\nsysId is used as index for (:Entity) nodes\n</code></pre>"},{"location":"module-db-management/#promg.modules.db_management.DBManagement.get_all_rel_types","title":"<code>get_all_rel_types()</code>","text":"<p>Get all relationship types that are present in Neo4j instance</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of strings with all relationship types present in the Neo4j instance</p>"},{"location":"module-db-management/#promg.modules.db_management.DBManagement.get_all_node_labels","title":"<code>get_all_node_labels()</code>","text":"<p>Get all node labels that are present in Neo4j instance</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>A list of strings with all node labels present in the Neo4j instance</p>"},{"location":"module-db-management/#promg.modules.db_management.DBManagement.get_statistics","title":"<code>get_statistics()</code>","text":"<p>Get the count of nodes per label and the count of relationships per type</p> <p>Returns:</p> Type Description <code>List[Dict[str, any]]</code> <p>A list containing dictionaries with the label/relationship and its count</p>"},{"location":"module-db-management/#promg.modules.db_management.DBManagement.print_statistics","title":"<code>print_statistics()</code>","text":"<p>Print the statistics nicely using tabulate</p>"},{"location":"module-exporter/","title":"Module: Exporter","text":""},{"location":"module-exporter/#promg.modules.exporter.Exporter","title":"<code>Exporter</code>","text":""},{"location":"module-exporter/#promg.modules.exporter.Exporter.get_event_log","title":"<code>get_event_log(entity_type, additional_event_attributes=None, additional_entity_attributes=None)</code>","text":"<p>Get an event log extracted from the EKG for a specific entity and return it</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <p>The type of the entity --&gt; contract states that it exists</p> required <code>additional_event_attributes</code> <code>Optional[List[str]]</code> <p>list of different attributes of event that should also be stored in the</p> <code>None</code> <code>additional_entity_attributes</code> <code>Optional[List[str]]</code> <p>list of different attributes of entity that should also be stored in the</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of events with its attributes in the form of a dictionary</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>when the entity has not been defined</p>"},{"location":"module-exporter/#promg.modules.exporter.Exporter.save_event_log","title":"<code>save_event_log(entity_type, additional_event_attributes=None, additional_entity_attributes=None)</code>","text":"<p>Create an event log extracted from the EKG from a specific entity and store it as a csv file</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The type of the entity</p> required <code>additional_event_attributes</code> <code>Optional[List[str]]</code> <p>list of different attributes of event that should also be stored in the event log</p> <code>None</code> <code>additional_entity_attributes</code> <code>Optional[List[str]]</code> <p>list of different attributes of entity that should also be stored in the</p> <code>None</code>"},{"location":"module-inference_engine/","title":"Module: Inference Engine","text":""},{"location":"module-inference_engine/#promg.modules.inference_engine.InferenceEngine","title":"<code>InferenceEngine</code>","text":""},{"location":"module-inference_engine/#promg.modules.inference_engine.InferenceEngine.match_entity_with_batch_position","title":"<code>match_entity_with_batch_position(entity_type, relative_position_type)</code>","text":"<p>Infer the batch position of a specific entity</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The type of the entity</p> required <code>relative_position_type</code> <code>str</code> <p>The type of the relative position</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>when the entity has not been defined</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; inference_engine.match_entity_with_batch_position(\n&gt;&gt;&gt;     entity_type=\"Box\",\n&gt;&gt;&gt;     relative_position_type=\"BatchPosition\")\nInfers the missing AT_POS relation between\n(:Box) and (:BatchPosition) nodes using rule shown below\n</code></pre> <p></p>"},{"location":"module-inference_engine/#promg.modules.inference_engine.InferenceEngine.infer_items_propagate_downwards_one_level","title":"<code>infer_items_propagate_downwards_one_level(entity_type)</code>","text":"<p>Infer items while propagating downwards one level</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The type of the entity</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>when the entity has not been defined</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; inference_engine.infer_items_propagate_downwards_one_level(entity_type=\"Box\")\nInfers the missing corr relation for the (:Box)\nentity using the rule shown below\n</code></pre> <p></p>"},{"location":"module-inference_engine/#promg.modules.inference_engine.InferenceEngine.infer_items_propagate_upwards_multiple_levels","title":"<code>infer_items_propagate_upwards_multiple_levels(entity_type, is_load=True)</code>","text":"<p>Infer items while propagating upwards multiple levels</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The type of the entity</p> required <code>is_load</code> <p>indicating whether we are inferring upwards to load events (true) or unload events (false)</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>when the entity has not been defined</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; inference_engine.infer_items_propagate_upwards_multiple_levels(entity_type=\"Box\")\nInfers the missing corr relation for the (:Box)\nentity using the rule shown below\n</code></pre> <p></p>"},{"location":"module-inference_engine/#promg.modules.inference_engine.InferenceEngine.infer_items_propagate_downwards_multiple_level_w_batching","title":"<code>infer_items_propagate_downwards_multiple_level_w_batching(entity_type, relative_position_type)</code>","text":"<p>Infer items while propagating downwards multiple levels with batching</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The type of the entity</p> required <code>relative_position_type</code> <code>str</code> <p>The type of the relative position</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>when the entity has not been defined in semantic header</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; inference_engine.infer_items_propagate_downwards_multiple_level_w_batching(\n&gt;&gt;&gt;    entity_type=\"Box\")\nInfers the missing corr relation for the (:Box)\nentity using the rule shown below\n</code></pre> <p></p>"},{"location":"module-process_discovery/","title":"Analysis Module: Process Discovery","text":""},{"location":"module-process_discovery/#promg.modules.process_discovery.ProcessDiscovery","title":"<code>ProcessDiscovery</code>","text":""},{"location":"module-process_discovery/#promg.modules.process_discovery.ProcessDiscovery.create_df_process_model","title":"<code>create_df_process_model(entity_type)</code>","text":"<p>Create a DF process model</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The type of the entity</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>when the entity has not been defined</p>"},{"location":"module-transformer/","title":"Module: Transformer","text":""},{"location":"module-transformer/#promg.modules.transformer.Transformer","title":"<code>Transformer</code>","text":"<p>A module to transform records in the record layer/subgraphs of the semantic layer into a semantic layer using the semantic header</p> <ul> <li>Nodes on the semantic layer are created based on records or a subgraph of the semantic layer</li> <li>Relationships on the semantic layer are created based on records or a subgraph of the semantic layer</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from promg.modules.transformer import Transformer\n&gt;&gt;&gt; from promg import SemanticHeader\n&gt;&gt;&gt; semantic_header_path = Path(f'json_files/{dataset_name}.json')\n&gt;&gt;&gt; semantic_header = SemanticHeader.create_semantic_header(semantic_header_path)\n&gt;&gt;&gt; transformer = Transformer()\nReturns the transformer module\n</code></pre>"},{"location":"module-transformer/#promg.modules.transformer.Transformer.create_nodes_by_records","title":"<code>create_nodes_by_records(node_types)</code>","text":"<p>Create nodes with node types using records. If no node types are defined, then all nodes types specified in the semantic header get created if they are created using records</p> <p>Parameters:</p> Name Type Description Default <code>node_types</code> <code>Optional[List[str]]</code> <p>An optional list of strings with the node types to be created         If the given node type is not constructed using a record, then it is ignored.</p> required <p>Examples:</p> <p>Create nodes for a specific list of node types</p> <pre><code>&gt;&gt;&gt; transformer.create_nodes_by_records([\"Event\", \"Activity\", \"Book\"])\nThe transformer creates the nodes with the types Event, Activity and Book\nas specified in semantic header in the Event Knowledge graph.\n</code></pre> <p>Create nodes for all node types specified in the semantic header</p> <pre><code>&gt;&gt;&gt; transformer.create_nodes_by_records()\nThe transformer creates the nodes that are constructed by a record\nas specified in the semantic header Event Knowledge graph.\n</code></pre>"},{"location":"module-transformer/#promg.modules.transformer.Transformer.create_relations_using_records","title":"<code>create_relations_using_records(relation_types)</code>","text":"<p>Create relationships with relation types using records. That is two nodes related to the same (:Record) node get a relation in between as specified in the semantic header. If no relation types are defined, then all relation types specified in the semantic header get created if they are created using records</p> <p>Parameters:</p> Name Type Description Default <code>relation_types</code> <code>Optional[List[str]]</code> <p>An optional list of strings with the relation types to be created             If the given relation type is not constructed using a record, then it is ignored.</p> required <p>Examples:</p> <p>Create nodes for a specific list of relation types</p> <pre><code>&gt;&gt;&gt; transformer.create_relations_using_records([\"MEMBER_OF\"])\nThe transformer creates the relationships between two nodes with the type MEMBER_OF\nas specified in semantic header in the Event Knowledge graph.\nMore specifically, a (:Member) node is related to a (:Library) node with a [:MEMBER_OF] relation\nwhen the (:Member) and (:Library) node are related to the same (:Record) node as specified in\nthe semantic header\n</code></pre> <p>Create nodes for all relationship types specified in the semantic header</p> <pre><code>&gt;&gt;&gt; transformer.create_relations_using_records()\nThe transformer creates the relationships that are constructed by a subgraph\nas specified in the semantic header Event Knowledge graph.\n</code></pre>"},{"location":"module-transformer/#promg.modules.transformer.Transformer.create_relations_using_relations","title":"<code>create_relations_using_relations(relation_types)</code>","text":"<p>Create relations with relation types using subgraph of semantic layer (relations). If no relation types are defined, then all relation types specified in the semantic header get created if they are created using a subgraph</p> <p>Parameters:</p> Name Type Description Default <code>relation_types</code> <code>Optional[List[str]]</code> <p>An optional list of strings with the relation types to be created.             If the given relation type is not constructed using a subgraph, then it is ignored.</p> required <p>Examples:</p> <p>Create nodes for a specific list of node types</p> <pre><code>&gt;&gt;&gt; transformer.create_relations_using_relations([\"BORROWED\"])\nThe transformer creates the relationship with the types BORROWED\nas specified in semantic header in the Event Knowledge graph.\n</code></pre> <p>Create nodes for all node types specified in the semantic header</p> <pre><code>&gt;&gt;&gt; transformer.create_relations_using_relations()\nThe transformer creates the relationship that are constructed by a subgraph\nas specified in the semantic header Event Knowledge graph.\n</code></pre>"},{"location":"module-transformer/#promg.modules.transformer.Transformer.create_df_edges","title":"<code>create_df_edges(entity_types=None, event_label='Event')</code>","text":"<p>For all nodes (nodes or reified relationship nodes) with entity_types create DF edges between (:Event) nodes matching event_label</p> <p>Parameters:</p> Name Type Description Default <code>entity_types</code> <code>List[str]</code> <p>Optional list of types for which we want to create the DF edges.           If none, then we create DF edges for all nodes as specified in the semantic header.           If for the given entity types the infer_df is False (or not specified) in the semantic header,           then it is ignored (i.e. no DF edges are created)</p> <code>None</code> <code>event_label</code> <code>str</code> <p>The label of the event nodes used to create the DF edges</p> <code>'Event'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.create_df_edges(entity_types=[\"Book\"], event_label=\"Event\")\n</code></pre>"},{"location":"module-transformer/#promg.modules.transformer.Transformer.merge_duplicate_df","title":"<code>merge_duplicate_df()</code>","text":"<p>Merge duplicate DF edges between the same nodes Only do this for the (reified) nodes in semantic header with merge_duplicate_df = true</p>"}]}